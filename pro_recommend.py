# -*- coding: utf-8 -*-
"""PRO RECOMMEND.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JA_wHySDfAV10JytyPiwHZjeBjUo2LFT
"""

from google.colab import drive
drive.mount('/content/drive')

"""**PRODUCT RECOMMENTATION BASED ON VISIUAL SIMILARITY**

The goal of this experiment is to make a very basic recommender system: for a 
given fashion product, we want to recommend products that look similar.

This kind of recommender system is often used when browsing shopping websites. They usually appear on product pages as a "you may also like" section.

The idea behind this recommender system is simple: if a customer is showing interest towards a product by browsing its page, he may also be interested by products that are similar.

**IMPORT AND PARAMETERS SETUP**
"""

import numpy as np 
import pandas as pd 
import os

# imports
from keras.applications import vgg16
from tensorflow.keras.utils import load_img
from tensorflow.keras.utils import img_to_array
from keras.models import Model
from keras.applications.imagenet_utils import preprocess_input

from PIL import Image
import os
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

import imageio
from keras.models import Model
from keras.applications import vgg16
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image, ImageOps, ImageFilter
import scipy.ndimage as ndi
from sklearn.metrics import classification_report, confusion_matrix

from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing import image
from keras.utils import plot_model

# parameters setup

imgs_path = "/content/drive/MyDrive/products/pro/style/"
imgs_model_width, imgs_model_height = 224,224

nb_closest_images = 5 # number of most similar images to retrieve

""" **LOAD THE VGG PRE-TRAINED MODEL FROM KERAS.**

Keras module contains several pre-trained models that can be  loaded very easily.

For our recommender system based on visual similarity, we need to load a Convolutional Neural Network (CNN) that will be able to interpret the image contents.

In this example we will load the VGG16 model trained on imagenet, a big labeled images database.

If we take the whole model, we will get an output containing probabilities to belong to certain classes, but that is not what we want.

We want to retrieve all the information that the model was able to get in the images.

In order to do so, we have to remove the last layers of the CNN which are only used for classes predictions.
"""

# load the model
vgg_model = vgg16.VGG16(weights='imagenet')

# remove the last layers in order to get features instead of predictions
feat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer("fc2").output)

# print the layers of the CNN
feat_extractor.summary()

"""**GET THE IMAGE PATH**"""

files = [imgs_path + x for x in os.listdir(imgs_path) if "png" in x]

print("number of images:",len(files))

"""**FEED AN ONE IMAGE IN TO THE CNN**

First we observe what output we get when putting one image into the CNN.

The following steps are:

1. loading the image
2. preparing the image to feed it into the CNN
3. get the CNN output which will correspond to the image features
"""

# load an image in PIL format
original = load_img(files[0], target_size=(imgs_model_width, imgs_model_height))
plt.imshow(original)
plt.show()
print("image loaded successfully!")

# convert the PIL image to a numpy array
# in PIL - image is in (width, height, channel)
# in Numpy - image is in (height, width, channel)

numpy_image = img_to_array(original)

# convert the image / images into batch format
# expand_dims will add an extra dimension to the data at a particular axis
# we want the input matrix to the network to be of the form (batchsize, height, width, channels)
# thus we add the extra dimension to the axis 0.

image_batch = np.expand_dims(numpy_image, axis=0)
print('image batch size', image_batch.shape)

# prepare the image for the VGG model

processed_image = preprocess_input(image_batch.copy())

# get the extracted features
img_features = feat_extractor.predict(processed_image)

print("features successfully extracted!")
print("number of image features:",img_features.size)
img_features

"""**FEED ALL IMAGE IN TO THE CNN**

We were able to do the feature extraction process for one image. Now let's do it for all our images!
"""

# load all the images and prepare them for feeding into the CNN

importedImages = []

for f in files:
    filename = f
    original = load_img(filename, target_size=(224, 224))
    numpy_image = img_to_array(original)
    image_batch = np.expand_dims(numpy_image, axis=0)
    
    importedImages.append(image_batch)
    
images = np.vstack(importedImages)

processed_imgs = preprocess_input(images.copy())

# extract the images features

imgs_features = feat_extractor.predict(processed_imgs)

print("features successfully extracted!")
imgs_features.shape

"""**COMPUTE COSINE SIMILARITIES**

Now that we have features for every image, we can compute similarity metrics between every image couple.

We will use here the cosine similarity metric.
"""

# compute cosine similarities between images

cosSimilarities = cosine_similarity(imgs_features)

# store the results into a pandas dataframe

cos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)
cos_similarities_df.head()

"""**RETRIEVE MOST SIMILARITIES**

The final step is to implement a function that, for any given product, returns the visually most similar products.
"""

def read_img(image_path):
    image = load_img(image_path,target_size=(224,224,3))
    image = img_to_array(image)
    image = image/222.
    return image

# function to retrieve the most similar products for a given one

def retrieve_most_similar_products(given_img):

    print("original product:")

    original = load_img(given_img, target_size=(imgs_model_width, imgs_model_height))
    plt.imshow(original)
    plt.show()

    print("-----------------------------------------------------------------------")
    print("most similar products:")

    closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index
    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]

    for _ in range(1):
      i = random.randint(1,len(closest_imgs))
      plt.figure(figsize = (4 , 4))
      plt.figure(figsize = (20 , 20))
    
    for i in range(1,len(closest_imgs)):
        plt.subplot(1 , 5, i)
        plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)
        original = load_img(closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))
        plt.imshow(original)
        plt.title(f'Similar Product #{i}')
        print("similarity score : ",closest_imgs_scores[i])

retrieve_most_similar_products(files[2])

retrieve_most_similar_products(files[5])

retrieve_most_similar_products(files[3])

retrieve_most_similar_products(files[21])

retrieve_most_similar_products(files[39])

retrieve_most_similar_products(files[19])

retrieve_most_similar_products(files[32])

retrieve_most_similar_products(files[25])

retrieve_most_similar_products(files[44])

retrieve_most_similar_products(files[27])

retrieve_most_similar_products(files[47])